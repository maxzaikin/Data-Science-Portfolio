{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9f10a94-07fc-4b6b-900b-0ca20d09122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import (\n",
    "    datasets,\n",
    "    layers\n",
    ")\n",
    "\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "416c2de1-ef85-44f1-b5dc-481892a73536",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test,y_test) = datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d53599bf-8425-452d-93d9-683dee395c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(imgs):\n",
    "    # make sure that the pixel values are scaled between 0 and 1\n",
    "    imgs = imgs.astype('float32') / 255.0\n",
    "    # change image size to 32x32 for easier manipulation of the tensor shape as it passes through the net.\n",
    "    imgs = np.pad(imgs,((0,0),(2,2),(2,2)), constant_values=0.0)\n",
    "    imgs = np.expand_dims(imgs,-1)\n",
    "\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55351441-f8f6-4696-9518-29a901f1c2b3",
   "metadata": {},
   "source": [
    "**FAQ**\n",
    "\n",
    "    -Q: What is Embeding?\n",
    "    -A: The embeding is a compression of the original image into a lower-dimensional latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a02590b4-a290-4880-93e3-34946e7a520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = preprocess(x_train)\n",
    "x_test = preprocess(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb1bf90-b4aa-438b-b81c-3b922ef44a65",
   "metadata": {},
   "source": [
    "# BUILD MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702d3d2d-c37d-45de-9069-2509b08b512a",
   "metadata": {},
   "source": [
    "## ENCODER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2cb6eb7-4198-49d9-9bb8-a21ced70030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = layers.Input(\n",
    "    shape=(32,32,1),\n",
    "    name='encoder_input'    \n",
    ")\n",
    "\n",
    "x = layers.Conv2D(\n",
    "    32,\n",
    "    (3,3),\n",
    "    strides=2,\n",
    "    activation='relu',\n",
    "    padding='same'\n",
    ")(encoder_input)\n",
    "\n",
    "x = layers.Conv2D(\n",
    "    64,\n",
    "    (3,3),\n",
    "    strides=2,\n",
    "    activation='relu',\n",
    "    padding='same'\n",
    ")(x)\n",
    "\n",
    "x = layers.Conv2D(\n",
    "    128,\n",
    "    (3,3),\n",
    "    strides=2,\n",
    "    activation='relu',\n",
    "    padding='same'\n",
    ")(x)\n",
    "\n",
    "shape_befoure_flattening = K.int_shape(x)[1:]\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "encoder_output = layers.Dense(2,name='encoder_output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7180ab-982a-4dc7-999d-2870991f5147",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
