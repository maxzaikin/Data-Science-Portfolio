{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d9e4fa-4537-406c-89f7-dbf7e03ca7c2",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8600ea52-768a-4bac-a788-53b311cf55f5",
   "metadata": {},
   "source": [
    "## INITIALIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc942bb-64bc-4acf-870b-65cebad04a4c",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "514987ff-ab57-41bd-9429-7efd0e048530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import (\n",
    "    layers,\n",
    "    models,\n",
    "    losses,\n",
    "    callbacks\n",
    ")\n",
    "import numpy as np\n",
    "import datetime\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db07681-d157-4b6a-a4e6-b615842891ae",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a050a5ca-5daf-41b1-941d-85fdb3a818f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_punctuation(s):\n",
    "    \"\"\"\n",
    "    Adds spaces around punctuation symbols in a string and normalizes whitespace.\n",
    "\n",
    "    This function takes an input string, identifies all punctuation characters,\n",
    "    and surrounds them with spaces. It then removes any instances of multiple\n",
    "    consecutive spaces, ensuring the string is neatly formatted.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    s : str\n",
    "        The input string to process.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    str\n",
    "        The processed string with spaces around punctuation and normalized whitespace.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> pad_punctuation(\"Hello,world! This is a test.\")\n",
    "    'Hello , world ! This is a test .'\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - The function uses Python's `string.punctuation` to identify all standard punctuation symbols.\n",
    "    - Regular expressions are used to handle the replacement efficiently.\n",
    "    \"\"\"\n",
    "    \n",
    "    # buld a puctuation symbol regular expression, and then replace coughted puctuation symbol with ' symbol '\n",
    "    s= re.sub(f'([{string.punctuation}])', r' \\1 ', s)\n",
    "    # replace all occurance of more the 1 whitespace in the row\n",
    "    return re.sub(' +', ' ', s)   \n",
    "\n",
    "def prepare_inputs(text):\n",
    "    \"\"\"\n",
    "    Prepares input and target tensors for a token prediction model.\n",
    "\n",
    "    This transformation processes a batch of text data to help the model learn to predict \n",
    "    the next token in a sentence by analyzing previous tokens within the same sentence.\n",
    "\n",
    "    Args:\n",
    "        text (tf.Tensor): A batch of raw text input, typically as a 1D tensor or list of strings.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple (x, y) where:\n",
    "            - x (tf.Tensor): The input tensor containing all tokens of each sentence \n",
    "              except the last token, with shape (batch_size, sequence_length-1).\n",
    "            - y (tf.Tensor): The target tensor containing all tokens of each sentence \n",
    "              starting from the second token, with shape (batch_size, sequence_length-1).\n",
    "    \n",
    "    Steps:\n",
    "        1. Expands the text tensor by adding a new dimension at the end.\n",
    "        2. Tokenizes the sentences using the provided `vectorize_layer`.\n",
    "        3. Splits the tokenized sentences into:\n",
    "            - `x`: All tokens except the last one.\n",
    "            - `y`: All tokens except the first one.\n",
    "    \"\"\"\n",
    "    # Add 1 dimension to the text data for compatibility with the vectorizer\n",
    "    text = tf.expand_dims(text, -1)\n",
    "    \n",
    "    # Tokenize sentences using the vectorize_layer (assumed to be predefined)\n",
    "    tokenized_sentences = vectorize_layer(text)\n",
    "\n",
    "    # Input tensor: all tokens except the last one\n",
    "    x = tokenized_sentences[:, :-1]\n",
    "    \n",
    "    # Target tensor: all tokens starting from the second one\n",
    "    y = tokenized_sentences[:, 1:]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def causal_attention_mask(batch_size, n_dest, n_src, dtype):\n",
    "    \"\"\"\n",
    "    Generates a causal attention mask for Transformer-based models.\n",
    "\n",
    "    A causal mask ensures that for each destination (decoder) token, the model can only\n",
    "    attend to source (encoder) tokens that have already been processed or align in time.\n",
    "    This is critical for tasks such as autoregressive generation where future tokens should\n",
    "    not be visible.\n",
    "\n",
    "    Args:\n",
    "        batch_size (int): Number of sequences in the batch.\n",
    "        n_dest (int): Number of destination tokens (e.g., in the decoder).\n",
    "        n_src (int): Number of source tokens (e.g., in the encoder or the decoder itself).\n",
    "        dtype (tf.DType): Data type for the resulting mask (e.g., `tf.float32`).\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: A mask tensor of shape `(batch_size, n_dest, n_src)` with values of 1.0\n",
    "                   for allowed positions and 0.0 for disallowed positions.\n",
    "    \"\"\"\n",
    "    # Create a range of indices for destination tokens and reshape to a column vector\n",
    "    i = tf.range(n_dest)[:, None]  # Shape: (n_dest, 1)\n",
    "    \n",
    "    # Create a range of indices for source tokens\n",
    "    j = tf.range(n_src)  # Shape: (n_src,)\n",
    "    \n",
    "    # Compare indices to establish causality: i >= j - offset\n",
    "    # This ensures the mask allows only past and current positions\n",
    "    # j - n_src + n_dest - computes an adjusted offset for the indices of the source tokens (j) to align them with the destination tokens (i).\n",
    "    # i >= (adjusted j) - 1. it is where the causality is enforced. The mask sets True when a destination token's index i is greater \n",
    "    #                     than or equal to the adjusted source token index j - n_src + n_dest.\n",
    "    #                     2. it  ensures that a destination token can \"see\" only the tokens in the source that come before it or align with it.\n",
    "    m = i >= j - n_src + n_dest  # Shape: (n_dest, n_src)\n",
    "    \n",
    "    # Cast the boolean mask into the specified dtype (e.g., float32 or float16)\n",
    "    mask = tf.cast(m, dtype)  # Shape: (n_dest, n_src)\n",
    "    \n",
    "    # Reshape the mask to add a singleton batch dimension\n",
    "    mask = tf.reshape(mask, [1, n_dest, n_src])  # Shape: (1, n_dest, n_src)\n",
    "    \n",
    "    # Calculate the multiplier for tiling the mask to match batch size\n",
    "    mult = tf.concat([tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)], 0)\n",
    "    # `mult` is a vector specifying how many times to replicate along each axis\n",
    "    \n",
    "    # Tile the mask along the batch dimension\n",
    "    return tf.tile(mask, mult)  # Final shape: (batch_size, n_dest, n_src)\n",
    "\n",
    "def print_probs(info, vocab, top_k=5):\n",
    "    \"\"\"\n",
    "    Prints the top-k predicted probabilities of words along with their attention scores\n",
    "    visualized as HTML for a given prompt and model output.\n",
    "\n",
    "    Args:\n",
    "        info (list of dicts): A list of dictionaries containing:\n",
    "            - 'prompt' (str): The input prompt sentence for which probabilities are being analyzed.\n",
    "            - 'atts' (np.ndarray): Attention scores corresponding to the words in the prompt.\n",
    "            - 'word_probs' (np.ndarray): Probabilities associated with each word in the vocabulary.\n",
    "        vocab (list of str): A list of vocabulary words indexed to match the probabilities.\n",
    "        top_k (int, optional): The number of top probabilities to display for each prompt. Defaults to 5.\n",
    "\n",
    "    Output:\n",
    "        Displays HTML to highlight words in the prompt based on their attention scores.\n",
    "        Prints the top-k most probable words from the vocabulary along with their probabilities.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Loop through each element in the info list.\n",
    "    for i in info:\n",
    "        highlighted_text = []  # Initialize an empty list to store HTML strings for highlighted words.\n",
    "\n",
    "        # Loop through each word in the prompt and its corresponding average attention score.\n",
    "        for word, att_score in zip(i['prompt'].split(), np.mean(i['atts'], axis=0)):\n",
    "            # Create a span element with a background color that varies based on the attention score.\n",
    "            highlighted_text.append(\n",
    "                '<span style=\"background-color:rgba(135,206,250,'\n",
    "                + str(att_score / max(np.mean(i[\"atts\"], axis=0)))  # Normalize attention score.\n",
    "                + ');\">'\n",
    "                + word\n",
    "                + \"</span>\"\n",
    "            )\n",
    "        \n",
    "        # Join the list of highlighted words into a single string.\n",
    "        highlighted_text = ' '.join(highlighted_text)\n",
    "        \n",
    "        # Display the HTML to visualize the attention scores as background color.\n",
    "        display(HTML(highlighted_text))\n",
    "\n",
    "        # Extract word probabilities for the current prompt.\n",
    "        word_probs = i['word_probs']\n",
    "        \n",
    "        # Sort the word probabilities in descending order and take the top-k.\n",
    "        p_sorted = np.sort(word_probs)[::-1][:top_k]\n",
    "        \n",
    "        # Get the indices of the top-k probabilities.\n",
    "        i_sorted = np.argsort(word_probs)[::-1][:top_k]\n",
    "\n",
    "        # Print the top-k words along with their probabilities (rounded to 2 decimal places).\n",
    "        for p, i in zip(p_sorted, i_sorted):\n",
    "            print(f'{vocab[i]}:    \\t{np.round(100 * p, 2)}%')\n",
    "\n",
    "        print('-----------\\n')  # Print a separator between different prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4762c44c-40ab-455a-b2aa-1165f491ab2d",
   "metadata": {},
   "source": [
    "## PREPARE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f305593d-e66e-4d26-8693-6bad88cd2eb4",
   "metadata": {},
   "source": [
    "### Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdde2842-336a-424a-923d-97fe65352d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!kaggle datasets download -d zynicide/wine-reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a6e370-48a3-4115-a409-65284cb782b7",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10f173f7-3700-4fb5-a516-4d1f5c003ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./datasets/wine-reviews/winemag-data-130k-v2.json') as json_data:\n",
    "    wine_data= json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7352e7-6643-4eed-b068-a0a0d011f957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wine_data[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff43c97-7d50-4d52-9c40-31038d0a7c4e",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84327d16-c973-4729-9a80-f63f29d8212d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter datasets\n",
    "filtered_data= [\n",
    "    'wine_review : ' + x['country'] + ' : ' + x['province'] + ' : ' + x['variety'] + ' : ' + x['description'] for x in wine_data \n",
    "    if x['country'] is not None\n",
    "       and x['province'] is not None\n",
    "       and x['variety'] is not None\n",
    "       and x['description'] is not None\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ef73e9f-42a7-40d9-893b-01e2274db65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wine_review : US : California : Cabernet Sauvignon : Soft, supple plum envelopes an oaky structure in this Cabernet, supported by 15% Merlot. Coffee and chocolate complete the picture, finishing strong at the end, resulting in a value-priced wine of attractive flavor and immediate accessibility.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aadca3d9-71c6-4a12-ac20-ac3cf453d907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129907 recepies loaded\n"
     ]
    }
   ],
   "source": [
    "n_wines= len(filtered_data)\n",
    "print(f'{n_wines} recepies loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5fca18-76c3-4d30-a74f-4d0751b57422",
   "metadata": {},
   "source": [
    "## TOKENIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc43c305-017c-41b7-a5fc-6e302557d10d",
   "metadata": {},
   "source": [
    "### Pad the punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9e57e1f-f804-4e61-8353-2be5683d0208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.56 s, sys: 10.2 ms, total: 3.57 s\n",
      "Wall time: 3.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ~3s\n",
    "text_data= [pad_punctuation(x) for x in filtered_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e411dad5-b63e-4ff0-8a08-1e3bc0e0a679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wine _ review : US : California : Pinot Noir : Oak and earth intermingle around robust aromas of wet forest floor in this vineyard - designated Pinot that hails from a high - elevation site . Small in production , it offers intense , full - bodied raspberry and blackberry steeped in smoky spice and smooth texture . '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data= text_data[25]\n",
    "example_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3560ef-4889-4dee-967e-80da846aaabd",
   "metadata": {},
   "source": [
    "### Convert to TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "81edd78b-aa76-4f04-99a9-00cd3482a692",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 22:09:54.060761: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 22:09:54.265071: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 22:09:54.265131: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 22:09:54.269764: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 22:09:54.269813: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 22:09:54.269834: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 22:09:54.542520: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 22:09:54.542879: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 22:09:54.542896: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-11-26 22:09:54.543017: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-26 22:09:54.543148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2245 MB memory:  -> device: 0, name: NVIDIA T1200 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Convert data to a TensorFlow dataset devided by batches with 32 recepies and shuffle buffer thus all recepies are devided randomly\n",
    "text_ds= (\n",
    "    tf.data.Dataset.from_tensor_slices(text_data).batch(32).shuffle(1000)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b386723-e206-40f0-8f2c-dd23ac75c8f5",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564c2457-1b36-4175-a764-870bba96a574",
   "metadata": {},
   "source": [
    "#### Create Vect. layer\n",
    "\n",
    "Create a Keras TextVectorization layer:\n",
    "- convert text to lowercase\n",
    "- give most prevalent 10k words a corresponding integer token\n",
    "- pad the sequnce to 81 tokens long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc9ef583-29ec-4b3c-9de2-e868fd67cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=10000\n",
    "MAX_LEN=80\n",
    "\n",
    "vectorize_layer= layers.TextVectorization(\n",
    "    standardize='lower',\n",
    "    max_tokens=VOCAB_SIZE,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=80 + 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb2a306-67fd-4776-a349-7b48dd677c6f",
   "metadata": {},
   "source": [
    "#### Calc text statistics\n",
    "\n",
    "- Apply TextVectorization to the training data\n",
    "- Get the vocabulary of 10k most pevalent words.  \n",
    "  NOTE:  \n",
    "  - all words over 10k will be coded as 1 (i.e. UNK)\n",
    "  - if number of words in sentence less then 201, thouse will be coded as 0 (i.e. stop token - text string come to an end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "35c94748-ecbc-4026-b160-07c082eee135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.4 s, sys: 3.64 s, total: 20.1 s\n",
      "Wall time: 19.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-26 22:34:27.669896: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# ~20s \n",
    "# Adapt layer to the training set\n",
    "vectorize_layer.adapt(text_ds)\n",
    "vocab=vectorize_layer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96806a46-2486-4460-9fd5-f6e9a7bbf7a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : \n",
      "1 : [UNK]\n",
      "2 : :\n",
      "3 : ,\n",
      "4 : .\n",
      "5 : and\n",
      "6 : the\n",
      "7 : wine\n",
      "8 : a\n",
      "9 : of\n"
     ]
    }
   ],
   "source": [
    "for i,word in enumerate(vocab[:10]):\n",
    "    print(f'{i} : {word}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432c9d4-32f7-4ec3-80c8-274781f38cba",
   "metadata": {},
   "source": [
    "INTERIM CONCLUSION\n",
    "\n",
    "We see a subset of tokens mapped to their respctive indices. The layer reserves the 0 token for padding, and 1 for unknown. NOTE:\n",
    "\n",
    "    The other words are assigned tokens in order of frequency\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c9f857e1-756c-4c80-a97e-4894d45dc337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wine _ review : US : Oregon : Pinot Gris : Tart and snappy , the flavors of lime flesh and rind dominate . Some green pineapple pokes through , with crisp acidity underscoring the flavors . The wine was all stainless - steel fermented . '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e888286-bb70-4a8a-a7ee-9e59a0442bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   7   11   10    2   21    2  151    2   44  411    2  139    5 1009\n",
      "    3    6   17    9  150 1030    5  681  627    4  105   95  235 6405\n",
      "   85    3   12   74   31 5782    6   17    4    6    7  440  128  879\n",
      "   15  797  542    4    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# display same as above but as converted to int word mappings\n",
    "example_tokenised=vectorize_layer(text_data[2])\n",
    "print(example_tokenised.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd077b8-11a6-4ad4-82b5-75a8cffff654",
   "metadata": {},
   "source": [
    "#### Create Training Dataset\n",
    "\n",
    "prepare_inputs convert the dataset to the MapDataset where each sentnce is splited on to the 2 sets of sequences:\n",
    "- x: contains all words in sentece except last\n",
    "- y: shifted by one left, thus it starts from the 2nd element\n",
    "\n",
    "Thus we will have a tuple `[x,y]` thus when our model will train it will learn relation ships between words as it nos that word `x` the target will be `y`. For example in sentence `The cloud is white` model will learn that `x=The` and `y=cloud` so it will adjust it weight accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "56597fbd-87c1-4f00-b09a-d65619db3360",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds= text_ds.map(prepare_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6cc5b18a-e79e-4bcc-9d36-f36694d4760e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(80,), dtype=int64, numpy=\n",
       "array([   7,   11,   10,    2,   41,    2,  333,   41,    2,  164,    2,\n",
       "         13,  187,  466,    9,  164,   76,   53,  796,  552,    9,   27,\n",
       "         26, 8090,   33,   73, 2925,   50,   20,  464,  289,   20,   95,\n",
       "        131,    4,    8,  109,    9,  214,  122,  908,  266,    6,    7,\n",
       "          8,   88,    3, 4671,  615,    4,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_output= train_ds.take(1).get_single_element()\n",
    "example_input_output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "65cc671c-2b50-4e7e-9e6a-643e7582148e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(80,), dtype=int64, numpy=\n",
       "array([   7,   11,   10,    2,   86,    2,  209,   86,    2,  272,    2,\n",
       "       1009,   37,    5,   60,   27,  328,    6, 1955,  683,    9,  341,\n",
       "          5,  741,    4,   16,  211,   57,    3,  343,    5,  181,    3,\n",
       "         12,   68,    5,  124,   60,   17,    4,    6,   32,  788,   97,\n",
       "          5,  103,    4,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input_output[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c62c6a-d7c0-4120-a3ce-f4f303004354",
   "metadata": {},
   "source": [
    "## BUILD MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ed590-ca80-47cb-a4e6-c765b37c6e83",
   "metadata": {},
   "source": [
    "### Causal attention mask\n",
    "\n",
    "<img src=\"./images/causal-masking.png\" width=\"600\" height=\"400\">\n",
    "\n",
    "\n",
    "**The attention score matrix for a sequence of words**\n",
    "\n",
    "- The green blocks at the top represent the queries — tokens for which the model is trying to predict the next token.\n",
    "- The red blocks on the left represent the keys — tokens that the model searches for relevant information.\n",
    "\n",
    "**Explanation of Causal Masking**\n",
    "- The gray area indicates where the causal mask is applied.\n",
    "- The purpose of the mask is to prevent \"information leakage\" from future words. Without this mask, our GPT model would be able to perfectly guess the next word in the sentence, because it would be using the key from the word itself as a feature. For example, when calculating attention for the word \"the\", the model can only use information from previous words, not the ones that come after.\n",
    "- The mask sets the attention weight for future words to 0. This explains why part of the matrix is gray for the first words like \"the,\" \"pink,\" and \"elephant.\"\n",
    "- Each word's vector is multiplied by the corresponding keys, but the attention to future tokens is blocked by the mask.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3ab1a0db-22cd-4efe-b123-2333d523b7a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]], dtype=int32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(causal_attentin_mask(1,10,10, dtype=tf.int32)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a35e74-980c-42d2-87ca-50a111f3db6a",
   "metadata": {},
   "source": [
    "### Transformer Block Layer\n",
    "\n",
    "<img src=\"./images/transformer-block.png\" width=\"500\" height=\"400\">\n",
    "\n",
    "A Transformer block is a single component within a Transformer that applies some skip connections, feed-forward (dense) layers, and normalization around the multihead attention layer.\n",
    "\n",
    "1. query is passed around the multihead attention layer to be added\n",
    "to the output—this is a skip connection and is common in modern deep learning\n",
    "architectures. It means we can build very deep neural networks that do not suffer as\n",
    "much from the vanishing gradient problem, because the skip connection provides a\n",
    "gradient-free highway that allows the network to transfer information forward\n",
    "uninterrupted.\n",
    "2. layer normalization is used in the Transformer block to provide stability to the\n",
    "training process. We have already seen the batch normalization layer in action throughout\n",
    "this book, where the output from each channel is normalized to have a mean of 0 and\n",
    "standard deviation of 1.\n",
    "3. Layer normalization. Each position within a sentence is normalized independently, but across the entire feature set for that position. This ensures that normalization happens independently for each word in a sentence, making it well-suited for sequential data like text. Use Case: Common in Transformers and other sequential models where the position-wise normalization provides stability and prevents dependencies on batch size.\n",
    "4. a set of feed-forward (i.e., densely connected) layers is included in the Transformer block, to allow the component to extract higher-level features as we go deeper into the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9ae6af92-ff21-4813-ab53-76f1034f47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    \"\"\"\n",
    "    TransformerBlock is a custom Keras layer that implements a single block of the Transformer model.\n",
    "    \n",
    "    Attributes:\n",
    "        num_heads (int): Number of attention heads in the Multi-Head Attention layer.\n",
    "        key_dim (int): Dimensionality of the query and key vectors in attention.\n",
    "        embed_dim (int): Dimensionality of the input and output embeddings.\n",
    "        ff_dim (int): Dimensionality of the hidden layer in the feed-forward network (FFN).\n",
    "        dropout_rate (float): Dropout rate applied after the attention and FFN layers.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, num_heads, key_dim, embed_dim, ff_dim, dropout_rate=0.1):\n",
    "        \"\"\"\n",
    "        Initializes the Transformer block with its components.\n",
    "\n",
    "        Args:\n",
    "            num_heads (int): Number of attention heads.\n",
    "            key_dim (int): Dimension of the query/key vectors.\n",
    "            embed_dim (int): Dimension of the output embeddings.\n",
    "            ff_dim (int): Dimension of the feed-forward layer.\n",
    "            dropout_rate (float): Dropout rate to prevent overfitting.\n",
    "        \"\"\"\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        # Store input parameters as instance variables\n",
    "        self.num_heads = num_heads\n",
    "        self.key_dim = key_dim\n",
    "        self.embed_dim = embed_dim\n",
    "        self.ff_dim = ff_dim\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        # Define a Multi-Head Attention layer with the given number of heads and key dimension\n",
    "        self.attn = layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, output_shape=embed_dim)\n",
    "\n",
    "        # Dropout layer applied after the attention mechanism\n",
    "        self.dropout_1 = layers.Dropout(rate=dropout_rate)\n",
    "\n",
    "        # Layer Normalization for the residual connection after attention\n",
    "        self.ln_1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # First layer of the Feed-Forward Network (FFN) with ReLU activation\n",
    "        self.ffn_1 = layers.Dense(units=ff_dim, activation='relu')\n",
    "\n",
    "        # Second layer of the Feed-Forward Network (FFN) to project back to the embedding dimension\n",
    "        self.ffn_2 = layers.Dense(units=embed_dim)\n",
    "\n",
    "        # Dropout layer applied after the FFN\n",
    "        self.dropout_2 = layers.Dropout(rate=dropout_rate)\n",
    "\n",
    "        # Layer Normalization for the residual connection after the FFN\n",
    "        self.ln_2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        \"\"\"\n",
    "        Forward pass of the Transformer block.\n",
    "        \n",
    "        Args:\n",
    "            inputs (tf.Tensor): Input tensor of shape (batch_size, seq_len, embed_dim).\n",
    "        \n",
    "        Returns:\n",
    "            tuple: A tuple containing:\n",
    "                - Output tensor of shape (batch_size, seq_len, embed_dim).\n",
    "                - Attention scores tensor (for visualization or analysis).\n",
    "        \"\"\"\n",
    "        # Get the shape of the input tensor to use in creating a causal mask\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size = input_shape[0]\n",
    "        seq_len = input_shape[1]\n",
    "\n",
    "        # Create a causal attention mask to prevent the model from looking at future tokens\n",
    "        causal_mask = causal_attention_mask(batch_size, seq_len, seq_len, tf.bool)\n",
    "\n",
    "        # Apply Multi-Head Attention and mask to the inputs\n",
    "        attention_output, attention_scores = self.attn(inputs, inputs, attention_mask=causal_mask, return_attention_scores=True)\n",
    "\n",
    "        # Apply dropout to the attention output\n",
    "        attention_output = self.dropout_1(attention_output)\n",
    "\n",
    "        # Apply Layer Normalization and add a residual connection (skip connection)\n",
    "        out1 = self.ln_1(inputs + attention_output)\n",
    "\n",
    "        # Pass the normalized output through the first FFN layer with ReLU activation\n",
    "        ffn_1 = self.ffn_1(out1)\n",
    "\n",
    "        # Pass the result through the second FFN layer to project it back to the embedding dimension\n",
    "        ffn_2 = self.ffn_2(ffn_1)\n",
    "\n",
    "        # Apply dropout to the FFN output\n",
    "        ffn_output = self.dropout_2(ffn_2)\n",
    "\n",
    "        # Apply Layer Normalization and add a residual connection (skip connection)\n",
    "        return (self.ln_2(out1 + ffn_output), attention_scores)\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Returns the configuration of the Transformer block for serialization.\n",
    "        \n",
    "        Returns:\n",
    "            dict: Configuration dictionary containing the layer's parameters.\n",
    "        \"\"\"\n",
    "        # Get the base configuration from the parent class and update it with additional parameters\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                'num_heads': self.num_heads,\n",
    "                'key_dim': self.key_dim,\n",
    "                'embed_dim': self.embed_dim,\n",
    "                'ff_dim': self.ff_dim,\n",
    "                'dropout_rate': self.dropout_rate\n",
    "            }\n",
    "        )\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c6eb1-fa91-4b95-9771-16fc24063642",
   "metadata": {},
   "source": [
    "### Token and Position Embedding\n",
    "\n",
    "The token embedding is to convert each token into a learned vector. We create the positional embedding, using a\n",
    "standard Embedding layer to convert each integer position into a learned vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76ae85fa-52ae-48e7-970c-0080ff9e300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    \"\"\"\n",
    "    Custom Keras layer that combines token embeddings and positional embeddings.\n",
    "\n",
    "    This layer maps input tokens and their positions into dense vectors of the same dimension,\n",
    "    which are then added together to produce the final embedding. This is typically used in \n",
    "    transformer-based models to provide both token and position information for sequential data.\n",
    "\n",
    "    Attributes:\n",
    "        max_len (int): Maximum sequence length of the input.\n",
    "        vocab_size (int): Size of the vocabulary for token embeddings.\n",
    "        embed_dim (int): Dimension of the embedding vectors.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_len, vocab_size, embed_dim):\n",
    "        \"\"\"\n",
    "        Initializes the TokenAndPositionEmbedding layer.\n",
    "\n",
    "        Args:\n",
    "            max_len (int): Maximum length of the input sequences.\n",
    "            vocab_size (int): Size of the vocabulary for the token embeddings.\n",
    "            embed_dim (int): Dimension of the output embedding vectors.\n",
    "        \"\"\"\n",
    "        # Call the parent constructor (Layer's __init__ method).\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "\n",
    "        # Store the maximum sequence length, vocabulary size, and embedding dimension.\n",
    "        self.max_len = max_len\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "        # Create the token embedding layer:\n",
    "        # Maps each token (word) index to a dense embedding vector of size embed_dim.\n",
    "        # This is an embedding layer that transforms token indices (e.g., words) into dense vectors of size embed_dim.\n",
    "        # Each token from the vocabulary is mapped to a unique vector.\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "\n",
    "        # Create the position embedding layer:\n",
    "        # Maps each position index (0, 1, 2, ...) to a dense embedding vector of size embed_dim.\n",
    "        # This embedding layer assigns a unique embedding vector to each position index in the input sequence. \n",
    "        # Positional embeddings help the model learn the order of tokens, which is essential for sequential tasks.\n",
    "        self.pos_emb = layers.Embedding(input_dim=max_len, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        \"\"\"\n",
    "        Combines token and positional embeddings for input sequences.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input tensor of token indices of shape (batch_size, sequence_length).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output tensor of shape (batch_size, sequence_length, embed_dim) with the \n",
    "            sum of token and positional embeddings.\n",
    "        \"\"\"\n",
    "        # Get the dynamic length of the input sequence (for padding or truncated sequences).\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "\n",
    "        # Create a tensor of position indices [0, 1, 2, ..., maxlen-1].\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "\n",
    "        # Generate position embeddings for each position index in the sequence.\n",
    "        positions = self.pos_emb(positions)\n",
    "\n",
    "        # Generate token embeddings for each token index in the input sequence.\n",
    "        x = self.token_emb(x)\n",
    "\n",
    "        # Add the token embeddings and positional embeddings element-wise.\n",
    "        return x + positions\n",
    "\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Returns the configuration of the layer for serialization.\n",
    "\n",
    "        Returns:\n",
    "            dict: Dictionary containing the configuration of the layer.\n",
    "        \"\"\"\n",
    "        # Get the configuration of the parent class and update it with custom attributes.\n",
    "        config = super().get_config()\n",
    "        config.update(\n",
    "            {\n",
    "                'max_len': self.max_len,\n",
    "                'vocab_size': self.vocab_size,\n",
    "                'embed_dim': self.embed_dim\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c65976-7b8b-4d0e-9e6b-c9767e2899fa",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "474342f6-2469-4673-9b60-5061bdccb394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for the model configuration.\n",
    "MAX_LEN = 80               # Maximum length of the input sequence (time steps).\n",
    "VOCAB_SIZE = 10000         # Size of the vocabulary (number of unique tokens).\n",
    "EMBEDDING_DIM = 256        # Dimension of the embedding space (size of each token embedding vector).\n",
    "N_HEADS = 2                # Number of attention heads in the multi-head attention mechanism.\n",
    "KEY_DIM = 256              # Dimension of the query, key, and value vectors in the attention mechanism.\n",
    "FEED_FORWARD_DIM = 256     # Dimension of the hidden layer in the feed-forward network within the transformer block.\n",
    "\n",
    "# Define the input layer for the model.\n",
    "# Input shape: (batch_size, sequence_length), where sequence_length is flexible (None).\n",
    "inputs = layers.Input(shape=(None,), dtype=tf.int32)  \n",
    "\n",
    "# Step 1: Apply token and position embeddings.\n",
    "# Inputs: token indices of shape (batch_size, sequence_length)\n",
    "# Outputs: Combined token and position embeddings of shape (batch_size, sequence_length, EMBEDDING_DIM)\n",
    "x = TokenAndPositionEmbedding(MAX_LEN, VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
    "\n",
    "# Step 2: Apply a transformer block to process the embeddings.\n",
    "# Inputs: Embedded tokens of shape (batch_size, sequence_length, EMBEDDING_DIM)\n",
    "# Outputs: \n",
    "#   - Processed embeddings of shape (batch_size, sequence_length, EMBEDDING_DIM)\n",
    "#   - Attention scores of shape (batch_size, N_HEADS, sequence_length, sequence_length)\n",
    "x, attention_scores = TransformerBlock(N_HEADS, KEY_DIM, EMBEDDING_DIM, FEED_FORWARD_DIM)(x)\n",
    "\n",
    "# Step 3: Apply a Dense layer to project the output to the vocabulary size.\n",
    "# This is typically used in language models for predicting the next token in a sequence.\n",
    "# Inputs: Processed embeddings of shape (batch_size, sequence_length, EMBEDDING_DIM)\n",
    "# Outputs: Probability distribution over vocabulary of shape (batch_size, sequence_length, VOCAB_SIZE)\n",
    "outputs = layers.Dense(VOCAB_SIZE, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9bebe6b0-1dc4-4da8-927d-c35fcb989fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with the Adam optimizer and a sparse categorical cross-entropy loss function.\n",
    "# SparseCategoricalCrossentropy is used because the labels are integer indices, not one-hot vectors.\n",
    "gpt= models.Model(inputs=inputs, outputs=[outputs, attention_scores])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf31fe-2888-43b8-bac8-e8a1803c7762",
   "metadata": {},
   "source": [
    "### Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "335785d8-3651-4c0d-a3a3-620b849a83f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.compile(\n",
    "    'adam',\n",
    "    loss=[losses.SparseCategoricalCrossentropy(), None]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3fff9a5f-20a9-4373-be76-70b3572a884e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ token_and_position_embedding_2  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,580,480</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TokenAndPositionEmbedding</span>)     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_1             │ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>),    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">658,688</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)] │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10000</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570,000</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ token_and_position_embedding_2  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │     \u001b[38;5;34m2,580,480\u001b[0m │\n",
       "│ (\u001b[38;5;33mTokenAndPositionEmbedding\u001b[0m)     │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_block_1             │ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m),    │       \u001b[38;5;34m658,688\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerBlock\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)] │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10000\u001b[0m)    │     \u001b[38;5;34m2,570,000\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,809,168</span> (22.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,809,168\u001b[0m (22.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,809,168</span> (22.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,809,168\u001b[0m (22.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpt.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2040a2-c5ca-4a38-9c39-b9b424fa0076",
   "metadata": {},
   "source": [
    "Token and Position Embedding:\n",
    "- VOCAB_SIZE * EMBEDDING_DIM for token embeddings.\n",
    "- MAX_LEN * EMBEDDING_DIM for positional embeddings.\n",
    "- 2,580,480 = (10,000 * 256) + (80 * 256).\n",
    "\n",
    "Transformer Block:\n",
    "- Multi-head attention and feed-forward network parameters.\n",
    "\n",
    "Dense Layer:\n",
    "- (EMBEDDING_DIM * VOCAB_SIZE) = (256 * 10,000) = 2,570,000.\n",
    "\n",
    "Dimensional Flow:\n",
    "- Input: (batch_size, sequence_length)\n",
    "- After Embedding: (batch_size, sequence_length, 256)\n",
    "- After Transformer: (batch_size, sequence_length, 256)\n",
    "- After Dense Layer: (batch_size, sequence_length, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f8671d5e-4be5-42c7-a4a1-bea3b6cd3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD_MODEL= False\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    gpt= models.load_model('./models/gpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c950d9ac-eeb8-4bf7-8d29-e81bff02fbae",
   "metadata": {},
   "source": [
    "## TRAIN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a4ab20-6f84-446d-80aa-84fa1ae059a4",
   "metadata": {},
   "source": [
    "### Text Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5b4cc25a-cd62-494b-aadf-c1bb78854c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(callbacks.Callback):\n",
    "    \"\"\"\n",
    "    A custom Keras callback for generating text during training.\n",
    "    \n",
    "    This callback generates text using the model's predictions after each training epoch.\n",
    "    \n",
    "    Args:\n",
    "        index_to_word (list): A list of words representing the vocabulary, where each index \n",
    "                              corresponds to a specific word.\n",
    "        top_k (int, optional): The number of top words to consider for sampling. Defaults to 10.\n",
    "    \n",
    "    Methods:\n",
    "        sample_from(probs, temperature):\n",
    "            Samples a word index from a probability distribution with temperature scaling.\n",
    "\n",
    "        generate(start_prompt, max_tokens, temperature):\n",
    "            Generates a sequence of text starting from a given prompt.\n",
    "\n",
    "        on_epoch_end(epoch, logs=None):\n",
    "            Called at the end of each epoch to generate text using the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, index_to_word, top_k=10):\n",
    "        \"\"\"\n",
    "        Initializes the TextGenerator callback.\n",
    "        \n",
    "        Args:\n",
    "            index_to_word (list): Vocabulary mapping from index to word.\n",
    "            top_k (int): Number of top predictions to consider for sampling. Defaults to 10.\n",
    "        \"\"\"\n",
    "        self.index_to_word = index_to_word  # Vocabulary list mapping indices to words.\n",
    "        # Create a reverse mapping from word to index for fast lookup.\n",
    "        self.word_to_index = {\n",
    "            word: index for index, word in enumerate(index_to_word)\n",
    "        }\n",
    "\n",
    "    def sample_from(self, probs, temperature):\n",
    "        \"\"\"\n",
    "        Samples an index from a probability distribution after scaling it with temperature.\n",
    "        \n",
    "        Args:\n",
    "            probs (np.ndarray): An array of probabilities for each vocabulary word.\n",
    "            temperature (float): The temperature value for controlling randomness in sampling.\n",
    "                                 A higher temperature increases diversity of generated text,\n",
    "                                 while lower values make it more deterministic.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A sampled index and the modified probability distribution.\n",
    "        \"\"\"\n",
    "        # Adjust the probability distribution using temperature scaling.\n",
    "        probs = probs ** (1 / temperature)\n",
    "        probs = probs / np.sum(probs)  # Normalize the probabilities.\n",
    "\n",
    "        # Sample an index from the adjusted probability distribution.\n",
    "        return np.random.choice(len(probs), p=probs), probs\n",
    "\n",
    "    def generate(self, start_prompt, max_tokens, temperature):\n",
    "        \"\"\"\n",
    "        Generates text starting from a prompt and continues until reaching max_tokens or an end token.\n",
    "        \n",
    "        Args:\n",
    "            start_prompt (str): The initial text prompt to start generating from.\n",
    "            max_tokens (int): The maximum number of tokens to generate.\n",
    "            temperature (float): Temperature value for controlling randomness during sampling.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of dictionaries containing information about each generated token,\n",
    "                  including its probability and attention scores.\n",
    "        \"\"\"\n",
    "        # Convert the start prompt into a list of token indices.\n",
    "        start_tokens = [self.word_to_index.get(x, 1) for x in start_prompt.split()]\n",
    "\n",
    "        sample_token = None  # Placeholder for the next sampled token.\n",
    "        info = []  # List to store information about each generated token.\n",
    "\n",
    "        # Continue generating tokens until reaching max_tokens or sampling an end token (index 0).\n",
    "        while len(start_tokens) < max_tokens and sample_token != 0:\n",
    "            # Convert the list of tokens into a NumPy array with shape (1, sequence_length).\n",
    "            x = np.array([start_tokens])\n",
    "\n",
    "            # Use the model to predict the next token and its attention scores.\n",
    "            y, att = self.model.predict(x, verbose=0)\n",
    "\n",
    "            # Sample the next token from the predicted probabilities.\n",
    "            sample_token, probs = self.sample_from(y[0][-1], temperature)\n",
    "\n",
    "            # Append information about the current generation step.\n",
    "            info.append(\n",
    "                {\n",
    "                    'prompt': start_prompt,        # Original prompt used.\n",
    "                    'word_probs': probs,           # Probability distribution for the next word.\n",
    "                    'atts': att[0, :, -1, :]       # Attention scores for the generated token.\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Add the sampled token to the list of tokens.\n",
    "            start_tokens.append(sample_token)\n",
    "\n",
    "            # Update the start prompt by appending the new word.\n",
    "            start_prompt = start_prompt + ' ' + self.index_to_word[sample_token]\n",
    "\n",
    "        # Print the final generated text after the loop completes.\n",
    "        print(f'\\ngenerated text:\\n{start_prompt}\\n')\n",
    "\n",
    "        return info\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Called automatically by Keras at the end of each training epoch.\n",
    "        Generates and prints a sample text starting from a predefined prompt.\n",
    "        \n",
    "        Args:\n",
    "            epoch (int): The current epoch number.\n",
    "            logs (dict, optional): A dictionary containing training metrics and information.\n",
    "        \"\"\"\n",
    "        self.generate('wine review', max_tokens=80, temperature=1.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b46a633-3b5d-4aca-83ae-c89d0415f301",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "55d93002-bb04-46ec-8666-8d9427ceb51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint_callback= callbacks.ModelCheckpoint(\n",
    "    filepath='./checkpoints/gpt-checkpoint.weights.h5',\n",
    "    save_weights_only=True,\n",
    "    save_freq='epoch',\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "30b9d2dc-ca86-40fa-b456-953fe30f2b2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 23:10:08.837500: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-27 23:10:08.837598: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-27 23:10:08.840660: I external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1239] Profiler found 1 GPUs\n",
      "2024-11-27 23:10:08.855489: E external/local_xla/xla/backends/profiler/gpu/cupti_error_manager.cc:137] cuptiGetTimestamp: error 999: \n",
      "2024-11-27 23:10:08.855632: E external/local_xla/xla/backends/profiler/gpu/cupti_error_manager.cc:186] cuptiSubscribe: ignored due to a previous error.\n",
      "2024-11-27 23:10:08.855638: E external/local_xla/xla/backends/profiler/gpu/cupti_error_manager.cc:223] cuptiGetResultString: ignored due to a previous error.\n",
      "2024-11-27 23:10:08.855695: E external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1281] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2024-11-27 23:10:08.856009: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n",
      "2024-11-27 23:10:08.856599: E external/local_xla/xla/backends/profiler/gpu/cupti_error_manager.cc:142] cuptiFinalize: ignored due to a previous error.\n",
      "2024-11-27 23:10:08.856669: E external/local_xla/xla/backends/profiler/gpu/cupti_error_manager.cc:223] cuptiGetResultString: ignored due to a previous error.\n",
      "2024-11-27 23:10:08.856684: E external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1373] function cupti_interface_->Finalize()failed with error \n"
     ]
    }
   ],
   "source": [
    "log_dir='./logs/fit/gpt/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "\n",
    "tensorboard_callback= callbacks.TensorBoard(\n",
    "    log_dir= log_dir,\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_images=False,\n",
    "    update_freq='epoch',\n",
    "    profile_batch=2,\n",
    "    embeddings_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd32b5f-7ad4-4059-8e12-25199b6c2942",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7788d5a1-57be-493c-85f5-53a6fe07bde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize starting prompt\n",
    "text_generator= TextGenerator(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbb1519-0e61-4891-b43a-35088600c6c4",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5f5507be-f2bf-4e44-8b48-a88c76ee7ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 23:13:51.088816: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-11-27 23:13:51.660976: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   4/4060\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:13\u001b[0m 63ms/step - loss: 8.7935"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 23:14:01.208333: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:104] Profiler session initializing.\n",
      "2024-11-27 23:14:01.208381: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:119] Profiler session started.\n",
      "2024-11-27 23:14:01.208401: E external/local_xla/xla/backends/profiler/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2024-11-27 23:14:01.208407: E external/local_xla/xla/backends/profiler/gpu/cupti_error_manager.cc:186] cuptiSubscribe: ignored due to a previous error.\n",
      "2024-11-27 23:14:01.208409: E external/local_xla/xla/backends/profiler/gpu/cupti_error_manager.cc:223] cuptiGetResultString: ignored due to a previous error.\n",
      "2024-11-27 23:14:01.208413: E external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1281] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error \n",
      "2024-11-27 23:14:01.262898: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:70] Profiler session collecting data.\n",
      "2024-11-27 23:14:01.271676: E external/local_xla/xla/backends/profiler/gpu/cupti_error_manager.cc:142] cuptiFinalize: ignored due to a previous error.\n",
      "2024-11-27 23:14:01.271736: E external/local_xla/xla/backends/profiler/gpu/cupti_error_manager.cc:223] cuptiGetResultString: ignored due to a previous error.\n",
      "2024-11-27 23:14:01.271742: E external/local_xla/xla/backends/profiler/gpu/cupti_tracer.cc:1373] function cupti_interface_->Finalize()failed with error \n",
      "2024-11-27 23:14:01.276334: E external/local_xla/xla/backends/profiler/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2024-11-27 23:14:01.276481: E external/local_xla/xla/backends/profiler/gpu/cupti_error_manager.cc:135] cuptiGetTimestamp: ignored due to a previous error.\n",
      "2024-11-27 23:14:01.276569: I external/local_xla/xla/backends/profiler/gpu/cupti_collector.cc:540]  GpuTracer has collected 0 callback api events and 0 activity events. \n",
      "2024-11-27 23:14:01.277812: I external/local_tsl/tsl/profiler/lib/profiler_session.cc:131] Profiler session tear down.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 378/4060\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:55\u001b[0m 31ms/step - loss: 3.8544"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_checkpoint_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_generator\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:321\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    319\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m    320\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[0;32m--> 321\u001b[0m \u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/keras/src/callbacks/callback_list.py:178\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_async_dispatch(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_train_batch_end, batch, logs)\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/keras/src/callbacks/callback_list.py:202\u001b[0m, in \u001b[0;36mCallbackList._on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    200\u001b[0m logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m callback \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks:\n\u001b[0;32m--> 202\u001b[0m     \u001b[43mcallback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_train_batch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/keras/src/callbacks/tensorboard.py:456\u001b[0m, in \u001b[0;36mTensorBoard.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(logs, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, value \u001b[38;5;129;01min\u001b[39;00m logs\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_step\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_trace:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/summary/tb_summary.py:303\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, data, step, description)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m TBNotInstalledError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.summary.scalar\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscalar_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorboard/plugins/scalar/summary_v2.py:88\u001b[0m, in \u001b[0;36mscalar\u001b[0;34m(name, data, step, description)\u001b[0m\n\u001b[1;32m     83\u001b[0m summary_scope \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mexperimental, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_scope\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39msummary_scope\n\u001b[1;32m     86\u001b[0m )\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m summary_scope(name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscalar_summary\u001b[39m\u001b[38;5;124m\"\u001b[39m, values\u001b[38;5;241m=\u001b[39m[data, step]) \u001b[38;5;28;01mas\u001b[39;00m (tag, _):\n\u001b[0;32m---> 88\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebugging\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massert_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39msummary\u001b[38;5;241m.\u001b[39mwrite(\n\u001b[1;32m     90\u001b[0m         tag\u001b[38;5;241m=\u001b[39mtag,\n\u001b[1;32m     91\u001b[0m         tensor\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mcast(data, tf\u001b[38;5;241m.\u001b[39mfloat32),\n\u001b[1;32m     92\u001b[0m         step\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m     93\u001b[0m         metadata\u001b[38;5;241m=\u001b[39msummary_metadata,\n\u001b[1;32m     94\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/ops/check_ops.py:2174\u001b[0m, in \u001b[0;36massert_scalar_v2\u001b[0;34m(tensor, message, name)\u001b[0m\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdebugging.assert_scalar\u001b[39m\u001b[38;5;124m'\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m\u001b[38;5;241m.\u001b[39madd_dispatch_support\n\u001b[1;32m   2156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massert_scalar_v2\u001b[39m(tensor, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   2157\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Asserts that the given `tensor` is a scalar.\u001b[39;00m\n\u001b[1;32m   2158\u001b[0m \n\u001b[1;32m   2159\u001b[0m \u001b[38;5;124;03m  This function raises `ValueError` unless it can be certain that the given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2172\u001b[0m \u001b[38;5;124;03m      unknown.\u001b[39;00m\n\u001b[1;32m   2173\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2174\u001b[0m   \u001b[43massert_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_target\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/ops/check_ops.py:2200\u001b[0m, in \u001b[0;36massert_scalar\u001b[0;34m(tensor, name, message)\u001b[0m\n\u001b[1;32m   2181\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Asserts that the given `tensor` is a scalar (i.e. zero-dimensional).\u001b[39;00m\n\u001b[1;32m   2182\u001b[0m \n\u001b[1;32m   2183\u001b[0m \u001b[38;5;124;03mThis function raises `ValueError` unless it can be certain that the given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2197\u001b[0m \u001b[38;5;124;03m    unknown.\u001b[39;00m\n\u001b[1;32m   2198\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massert_scalar\u001b[39m\u001b[38;5;124m'\u001b[39m, [tensor]) \u001b[38;5;28;01mas\u001b[39;00m name_scope:\n\u001b[0;32m-> 2200\u001b[0m   tensor \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname_scope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2201\u001b[0m   shape \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mget_shape()\n\u001b[1;32m   2202\u001b[0m   message \u001b[38;5;241m=\u001b[39m _message_prefix(message)\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m Trace(trace_name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:713\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    712\u001b[0m preferred_dtype \u001b[38;5;241m=\u001b[39m preferred_dtype \u001b[38;5;129;01mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor_conversion_registry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreferred_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccepted_result_types\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconversion_func\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m for type \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactual = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mret\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mbase_dtype\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[38;5;241m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mconversion_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_ref\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/framework/constant_tensor_conversion.py:29\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constant_op  \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     28\u001b[0m _ \u001b[38;5;241m=\u001b[39m as_ref\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconstant_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstant\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/ops/weak_tensor_ops.py:142\u001b[0m, in \u001b[0;36mweak_tensor_binary_op_wrapper.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mis_auto_dtype_conversion_enabled():\n\u001b[0;32m--> 142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   bound_arguments \u001b[38;5;241m=\u001b[39m signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    144\u001b[0m   bound_arguments\u001b[38;5;241m.\u001b[39mapply_defaults()\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:276\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, v1\u001b[38;5;241m=\u001b[39m[])\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconstant\u001b[39m(\n\u001b[1;32m    179\u001b[0m     value, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    180\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ops\u001b[38;5;241m.\u001b[39mOperation, ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase]:\n\u001b[1;32m    181\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mallow_broadcast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.constant\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    288\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 289\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_constant_eager_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m const_tensor \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39m_create_graph_constant(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    292\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    293\u001b[0m )\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:301\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_constant_eager_impl\u001b[39m(\n\u001b[1;32m    298\u001b[0m     ctx, value, dtype, shape, verify_shape\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ops\u001b[38;5;241m.\u001b[39m_EagerTensorBase:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m   t \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_to_eager_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m shape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/miniconda3/envs/tensrnv/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gpt.fit(\n",
    "    train_ds,\n",
    "    epochs=5,\n",
    "    callbacks=[\n",
    "        model_checkpoint_callback,\n",
    "        tensorboard_callback,\n",
    "        text_generator\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c57a6d9-63e1-423c-aa71-d26a5578ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt.save('./models/gpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e3f937-e671-4e0f-92f9-bbb1eea96b10",
   "metadata": {},
   "source": [
    "## GENERATE TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fe12ae-d21f-4e39-8574-99903242aed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "info= text_generator.generate('wine review: italy', max_tokens=80, temperature=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f83c27c-5cd8-45fb-98ea-ac7043649d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "info= text_generator.generate('wine review: germany', max_tokens=80, temperature=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f883e3-b7b8-4121-8e10-2734730ca6ff",
   "metadata": {},
   "source": [
    "## REFERENCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f892aee-459a-4e9b-af93-7ef8a0405f52",
   "metadata": {},
   "source": [
    "1. [Generative Deep Learning, 2nd Edition](https://www.oreilly.com/library/view/generative-deep-learning/9781098134174/): David Foster's book from which has become an inspiration of this notebook.\n",
    "2. [David Foster](https://github.com/davidADSP): GitHub page\n",
    "3. [David Foster (Keynote) - Generative Deep Learning -Key To Unlocking Artificial General Intelligence?](https://www.youtube.com/watch?v=rHLf78CmNmQ): David's video session at Youtube regarding some key concepts has written in his book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4eb1eb-c565-477a-b890-1c25dbd65dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
