{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b883e2f4-a8b9-466d-a634-0539f2266472",
   "metadata": {},
   "source": [
    "# ENERGY BASE MODELS (EBM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38b7e24-66da-43ab-a6f5-9020bd92e45a",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ddd0bd49-1baf-4c62-bfdd-f7523bf58ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import (\n",
    "    datasets,\n",
    "    layers,\n",
    "    activations,\n",
    "    models,\n",
    "    \n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec50b1a0-b2d0-4e32-8523-4e836fafba6c",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c582f0f9-cb46-45d2-b503-ce2a4faf0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(imgs):\n",
    "    imgs= (imgs.astype('float32') - 127.5) / 127.5\n",
    "\n",
    "    # (0,0) - means do not change number of images in the batch\n",
    "    # (2,2),(2,2) - means create a frame thick=2\n",
    "    # constant_values - means fill fram with -1.0\n",
    "    imgs = np.pad(imgs, ((0,0), (2,2), (2,2)), constant_values=-1.0 )\n",
    "    imgs = np.expand_dims(imgs, -1)\n",
    "\n",
    "    return imgs\n",
    "\n",
    "def sample_batch(dataset):\n",
    "    batch= dataset.take(1).get_single_element()\n",
    "\n",
    "    if isinstance(batch, tuple):\n",
    "        batch= batch[0]\n",
    "\n",
    "    return batch.numpy()\n",
    "\n",
    "\n",
    "def display_mnist_img_tf(img_tf):\n",
    "\n",
    "    if img_tf.max() > 1.0:\n",
    "        img_tf= img_tf / 255.0\n",
    "    elif img_tf.min() < 0.0:\n",
    "        img_tf= (img_tf + 1.0) / 2.0\n",
    "        \n",
    "    plt.figure(figsize=(3,3))\n",
    "    plt.imshow(img_tf[0].astype('float32'))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd702d1-adf0-4d5d-99b3-0325f4121cde",
   "metadata": {},
   "source": [
    "## LOAD AND PRE-PROCESS DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6d48359-f422-4cd0-9aeb-13aa3dc82bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 686 ms, sys: 198 ms, total: 884 ms\n",
      "Wall time: 916 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "batch_size= 128\n",
    "\n",
    "(x_train, _), (x_test, _) = datasets.mnist.load_data()\n",
    "\n",
    "x_train= preprocess_img(x_train)\n",
    "x_test= preprocess_img(x_test)\n",
    "\n",
    "x_train= tf.data.Dataset.from_tensor_slices(x_train).batch(batch_size)\n",
    "x_test= tf.data.Dataset.from_tensor_slices(x_test).batch(batch_size)\n",
    "\n",
    "display_mnist_img_tf(sample_batch(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb412fa8-3f64-4ce6-9178-60345ca5e07f",
   "metadata": {},
   "source": [
    "## EBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298029d3-d863-4ed7-b676-b99cfccbee51",
   "metadata": {},
   "source": [
    "### NN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d90a3c3-d7bc-4474-b230-95fd7d4e6af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)       │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m16,448\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,993</span> (300.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m76,993\u001b[0m (300.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">76,993</span> (300.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m76,993\u001b[0m (300.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_size= 32\n",
    "ch_n= 1\n",
    "\n",
    "ebm_input= layers.Input(\n",
    "    shape=(img_size, img_size, ch_n)\n",
    ")\n",
    "\n",
    "x= layers.Conv2D(\n",
    "    16,\n",
    "    kernel_size=5,\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    activation= activations.swish\n",
    ")(ebm_input)\n",
    "\n",
    "x= layers.Conv2D(\n",
    "    32,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    activation=activations.swish\n",
    ")(x)\n",
    "x= layers.Conv2D(\n",
    "    64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    activation=activations.swish\n",
    ")(x)\n",
    "x= layers.Conv2D(\n",
    "    64,\n",
    "    kernel_size=3,\n",
    "    strides=2,\n",
    "    padding='same',\n",
    "    activation=activations.swish\n",
    ")(x)\n",
    "\n",
    "x= layers.Flatten()(x)\n",
    "x= layers.Dense(\n",
    "    64,\n",
    "    activation= activations.swish\n",
    ")(x)\n",
    "\n",
    "ebm_output= layers.Dense(1)(x)\n",
    "\n",
    "model= models.Model(ebm_input, ebm_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9724c83b-efb8-4013-b4de-8f0458469351",
   "metadata": {},
   "source": [
    "### Langevin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e5dfaa0-35ed-442f-810d-9370490fe7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(model, in_imgs, steps, step_size, noise, return_img_per_step=False):\n",
    "    imgs_per_step= []\n",
    "\n",
    "    for _ in range(steps):\n",
    "        in_imgs += tf.random.normal(in_imgs.shape, mean=0, stddev=noise)\n",
    "        in_imgs = tf.clip_by_value(in_imgs, -1.0, 1.0)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(in_imgs)\n",
    "            out_score= model(in_imgs)\n",
    "\n",
    "        grads= tape.gradient(out_score, in_imgs)\n",
    "        grads= tf.clip_by_value(in_imgs, -1.0, 1.0)\n",
    "\n",
    "        if return_img_per_step:\n",
    "            imgs_per_step.append(in_imgs)\n",
    "            \n",
    "    if return_img_per_step:\n",
    "        return tf.stack(imgs_per_step, axis=0)\n",
    "    else:\n",
    "        return in_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aec6d1d-05e6-401a-853c-e5c6ef78ab23",
   "metadata": {},
   "source": [
    "### Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c63cc0-e839-46cb-bb62-66ce3e06d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size= 8192\n",
    "\n",
    "class Buffer:\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model=model\n",
    "        self.examples= [\n",
    "            tf.random.uniform(shape=(img_size, img_size, ch_n)) * 2 -1 for _ in range(batch_size)\n",
    "        ]\n",
    "\n",
    "    def sample_new_examples(self, steps, step_size, noise):\n",
    "        n_new= np.random.binomial(batch_size, noise)\n",
    "        random_imgs= (\n",
    "            tf.random.uniform(\n",
    "                (\n",
    "                    n_new, \n",
    "                    img_size, \n",
    "                    img_size, \n",
    "                    ch_n\n",
    "                )\n",
    "            ) * 2 -1)\n",
    "        \n",
    "        old_imgs= tf.concat(\n",
    "            random.choices(\n",
    "                self.examples, \n",
    "                k=batch_size - n_new\n",
    "            ), axis=0)\n",
    "        \n",
    "        inp_imgs= tf.concat(\n",
    "            [\n",
    "                rand_imgs, \n",
    "                old_imgs\n",
    "            ], axis=0)\n",
    "        \n",
    "        inp_imgs= generate_samples(\n",
    "            self.model, \n",
    "            inp_imgs,\n",
    "            steps=step,\n",
    "            step_size=step_size,\n",
    "            noise=noise\n",
    "        )\n",
    "\n",
    "        self.examples= tf.split(\n",
    "            inp_imgs,\n",
    "            batch_size,\n",
    "            axis=0\n",
    "        ) + self.examples\n",
    "\n",
    "        self.examples= self_examples[:buffer_size]\n",
    "\n",
    "        return inp_imgs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6f271-031c-4437-90e1-35d9c4d34ce6",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13360a6-febf-4f41-a849-625a2646020a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
